# Toxicity-Challenge
This repository contains the various approaches to solve the Kaggle competion to identify toxicity of comments in social media.

|      Model                  | Private LB Score(25% Test Data)| Public LB Score(25% Test Data) 
| --------------------------- | -------------------------------| -------------------------------|
| Attention Model & Glove     |      0.9804                    |      0.9814
| Attention Model & ConceptNet|      0.9820                    |      0.9827
| Attention Model & FastText  |      0.9788                    |      0.9786
| With XGB                    |      0.9696                    |      0.9703
