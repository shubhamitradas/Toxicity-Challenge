{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled8.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shubhamitradas/Toxicity-Challenge/blob/master/service/predictors/predictor.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "MJJ7AqqSqXVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "48cbca19-22f5-4b6d-9672-177c6fbc6c55"
      },
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "from allennlp.common.util import JsonDict, sanitize\n",
        "from allennlp.data import DatasetReader, Instance\n",
        "from allennlp.data.tokenizers import WordTokenizer\n",
        "from allennlp.models import Model\n",
        "from allennlp.service.predictors.predictor import Predictor\n",
        "\n",
        "\n",
        "@Predictor.register('toxic')\n",
        "class ToxicPredictor(Predictor):\n",
        "    def __init__(self, model: Model, dataset_reader: DatasetReader) -> None:\n",
        "        super().__init__(model, dataset_reader)\n",
        "        self._tokenizer = WordTokenizer()\n",
        "\n",
        "    def _json_to_instance(self, json: JsonDict) -> Instance:\n",
        "        # We're overriding `predict_json` directly, so we don't need this.  But I'd rather have a\n",
        "        # useless stub here then make the base class throw a RuntimeError instead of a\n",
        "        # NotImplementedError - the checking on the base class is worth it.\n",
        "        raise RuntimeError(\"this should never be called\")\n",
        "\n",
        "    def predict_json(self, inputs: JsonDict, cuda_device: int = -1) -> JsonDict:\n",
        "        batch_json = [inputs]\n",
        "        batch_predictions = self.predict_batch_json(batch_json, cuda_device)\n",
        "        return batch_predictions[0]\n",
        "\n",
        "    def predict_batch_json(self, inputs: List[JsonDict], cuda_device: int = -1) -> List[JsonDict]:\n",
        "        instances = [\n",
        "            self._dataset_reader.text_to_instance(input['text'])\n",
        "            for input in inputs\n",
        "        ]\n",
        "\n",
        "        outputs = self._model.forward_on_instances(instances, cuda_device)\n",
        "\n",
        "        for input, output in zip(inputs, outputs):\n",
        "            output['id'] = input['id']\n",
        "\n",
        "        return sanitize(outputs)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/service/predictors/__init__.py:24: FutureWarning: allennlp.service.predictors.* has been depreciated. Please use allennlp.predictors.*\n",
            "  \"Please use allennlp.predictors.*\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/allennlp/service/predictors/predictor.py:6: FutureWarning: allennlp.service.predictors.* has been deprecated. Please use allennlp.predictors.*\n",
            "  \" Please use allennlp.predictors.*\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}