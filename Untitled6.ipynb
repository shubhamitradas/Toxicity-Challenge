{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/shubhamitradas/Toxicity-Challenge/blob/master/Untitled6.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "uvtBtloLTHjH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Reads the toxic data dataset from a csv, where the data looks like\n",
        "comment_id,comment_text,toxic,severe_toxic,obscene,threat,insult,identity_hate\n",
        "where the last 6 label columns are all 0 or 1\n",
        "(and where a comment can have multiple labels)\n",
        "\"\"\"\n",
        "from typing import List, Dict\n",
        "import csv\n",
        "import sys\n",
        "\n",
        "import tqdm\n",
        "from allennlp.common import Params\n",
        "from allennlp.common.checks import ConfigurationError\n",
        "from allennlp.data import DatasetReader,dataset, Instance\n",
        "from allennlp.data.fields import TextField, LabelField, ListField\n",
        "from allennlp.data.tokenizers import Tokenizer, WordTokenizer\n",
        "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
        "\n",
        "# One of the fields is really long\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "@DatasetReader.register('toxic')\n",
        "class ToxicReader(DatasetReader):\n",
        "    \"\"\"\n",
        "    toxic\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 max_length: int = None,\n",
        "                 tokenizer: Tokenizer = None,\n",
        "                 token_indexers: Dict[str, TokenIndexer] = None) -> None:\n",
        "        self.max_length = max_length\n",
        "        self._tokenizer = tokenizer or WordTokenizer()\n",
        "        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
        "\n",
        "    @classmethod\n",
        "    def from_params(cls, params: Params) -> 'ToxicReader':\n",
        "        tokenizer = Tokenizer.from_params(params.pop('tokenizer', {}))\n",
        "        token_indexers = TokenIndexer.dict_from_params(params.pop('token_indexers', {}))\n",
        "        max_length = params.pop('max_length', None)\n",
        "        params.assert_empty(cls.__name__)\n",
        "        return cls(max_length=max_length, tokenizer=tokenizer, token_indexers=token_indexers)\n",
        "\n",
        "    def read(self, file_path: str) -> dataset:\n",
        "        instances = []\n",
        "        with open(file_path, \"r\") as data_file:\n",
        "            reader = csv.reader(data_file)\n",
        "            for row in tqdm.tqdm(reader):\n",
        "                _, text, *labels = row\n",
        "                instances.append(self.text_to_instance(text, labels))\n",
        "        if not instances:\n",
        "            raise ConfigurationError(\"No instances read!\")\n",
        "\n",
        "        return dataset(instances)\n",
        "\n",
        "    # pylint: disable=arguments-differ\n",
        "    def text_to_instance(self,\n",
        "                         text: str,\n",
        "                         labels: List[str] = None) -> Instance:\n",
        "        # There is a pathological example in the test set.\n",
        "        if self.max_length is not None:\n",
        "            text = text[:self.max_length]\n",
        "        tokenized_text = self._tokenizer.tokenize(text)\n",
        "        text_field = TextField(tokenized_text, self._token_indexers)\n",
        "\n",
        "        fields = {'text': text_field}\n",
        "\n",
        "        # Normally we wouldn't do this, but we need the test instances to have\n",
        "        # the same \"shape\" as the train instances so that we can combine them\n",
        "        # all into a single dataset.\n",
        "        if not labels:\n",
        "            labels = [0, 0, 0, 0, 0, 0]\n",
        "\n",
        "        toxic, severe_toxic, obscene, threat, insult, identity_hate = labels\n",
        "\n",
        "        # Because the labels are already 0 or 1, skip_indexing.\n",
        "        fields['labels'] = ListField([\n",
        "            LabelField(int(toxic),         skip_indexing=True),\n",
        "            LabelField(int(severe_toxic),  skip_indexing=True),\n",
        "            LabelField(int(obscene),       skip_indexing=True),\n",
        "            LabelField(int(threat),        skip_indexing=True),\n",
        "            LabelField(int(insult),        skip_indexing=True),\n",
        "            LabelField(int(identity_hate), skip_indexing=True)\n",
        "        ])\n",
        "\n",
        "        return Instance(fields)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}